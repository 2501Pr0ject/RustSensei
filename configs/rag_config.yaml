# Configuration RAG pour RustSensei
# ==================================

# Embedding model
embeddings:
  model: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
  dimension: 384
  normalize: true
  batch_size: 32
  device: "mps"  # Apple Silicon

# Index FAISS
index:
  type: "IndexFlatIP"  # Inner Product (avec normalisation = cosine similarity)
  path: "rag/index/rustsensei.faiss"
  metadata_path: "rag/index/metadata.pkl"

# Chunking des documents
chunking:
  method: "markdown_sections"  # Chunking par sections markdown
  min_tokens: 100              # Merge si < min_tokens
  max_tokens: 1000             # Split si > max_tokens
  target_tokens: 500           # Taille cible
  include_code_blocks: true    # Inclure les blocs de code dans les chunks

# Sources de documents (M2 v0)
sources:
  - name: "Rust Book"
    id: "book"
    type: "markdown"
    path: "rag/docs/book/src"
    enabled: true

  - name: "Rust by Example"
    id: "rbe"
    type: "markdown"
    path: "rag/docs/rbe/src"
    enabled: true

  - name: "Rust Reference"
    id: "reference"
    type: "markdown"
    path: "rag/docs/reference/src"
    enabled: true

# Retrieval settings
retrieval:
  top_k: 5               # Nombre de chunks à récupérer
  score_threshold: 0.3   # Score minimum (cosine similarity)
  max_citations: 4       # Citations max à afficher

# Augmentation du prompt
augmentation:
  template: |
    Contexte de la documentation Rust officielle :
    {context}

    ---
    Question : {query}

  max_context_tokens: 1500
  citation_format: "[{source} — {heading}]"
